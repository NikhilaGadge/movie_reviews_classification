{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2"
      ],
      "metadata": {
        "id": "dZy4VxPBwhLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 2:  \n",
        "Due date: Monday, June 16 (23:59 CET)  \n",
        "Deliverable: One .py-file uploaded to Moodle  \n"
      ],
      "metadata": {
        "id": "lMXni_ijwlVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The tasks**"
      ],
      "metadata": {
        "id": "V3IIdoGYwp_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1\n",
        "1. The Natural Language Toolkit (NLTK) provides in its corpus collection a corpus of movie reviews with 1.000 positive and 1.000 negative reviews. Import these reviews by first making the NLTK available and then: import nltk from nltk.corpus import movie_reviews (1 point)"
      ],
      "metadata": {
        "id": "u3LqSoiJwxCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n",
        "!pip install emoji\n",
        "!pip install textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O550RXYeFHP9",
        "outputId": "d6e2e846-0988-47b3-8c34-d3d667ff13dd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.11/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.11/dist-packages (0.7.7)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.11/dist-packages (from textstat) (0.17.2)\n",
            "Requirement already satisfied: cmudict in /usr/local/lib/python3.11/dist-packages (from textstat) (1.0.32)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (8.7.0)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.22.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import movie_reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dcPQcaIwwSD",
        "outputId": "e49d3852-3a7a-4177-9a47-c58f051e7960"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4MS4eNAvwDVW",
        "outputId": "55b18216-68e3-4857-c93e-d885747d3522"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg/cv000_29416.txt',\n",
              " 'neg/cv001_19502.txt',\n",
              " 'neg/cv002_17424.txt',\n",
              " 'neg/cv003_12683.txt',\n",
              " 'neg/cv004_12641.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Display the first 5 fileids in the movie_reviews corpus\n",
        "movie_reviews.fileids()[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the first five documents are txt files. Hence we will read the reviews from each document in later steps"
      ],
      "metadata": {
        "id": "QRAU_UtUMf4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of reviews\n",
        "len(movie_reviews.fileids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fq5BUycyDot",
        "outputId": "0694de07-3ebb-4a10-e298-ed6f61fe1ae7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Review categories\n",
        "movie_reviews.categories()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taE-bYiNyfpz",
        "outputId": "bc58f060-99a2-4b03-9937-b3fda26ad2fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg', 'pos']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of positive reviews\n",
        "num_positive_reviews = len(movie_reviews.fileids('pos'))\n",
        "num_positive_reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tRwZwKTyg5r",
        "outputId": "c25944d5-703f-4444-e49a-cbdedfe51e0f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of positive reviews\n",
        "num_negative_reviews = len(movie_reviews.fileids('neg'))\n",
        "num_negative_reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI_RJgWtyiXy",
        "outputId": "17c53254-3bbc-4cc0-d215-9780ef5266f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the number of positive and negative reviews with matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(['Positive', 'Negative'], [num_positive_reviews, num_negative_reviews], color=['green', 'blue'])\n",
        "plt.title('Number of Positive and Negative Reviews in Movie Reviews Dataset')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "collapsed": true,
        "id": "OnV22uAkynes",
        "outputId": "8b12c087-7c6a-4ae3-909b-496b1c54ae41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2 and 3\n",
        "2. Read some of these reviews and, based on your impression about typical expressions used, define your own feature set for classifying the reviews as being positive (+) or negative (âˆ’). (2 points)\n",
        "\n",
        "3. Bonus task: Instead of determining your features based on your reading experience, develop a more sophisticated approach of feature identification. (3 points)"
      ],
      "metadata": {
        "id": "JSm8HgdoxtQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the movie_reviews dataset\n",
        "# Iterate over categories, iterate over every document in each category,\n",
        "# create a list of tuples ([reviews], [category name of reviews])\n",
        "\n",
        "documents_raw = [(movie_reviews.raw(fileid), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]"
      ],
      "metadata": {
        "id": "kJdAuKnyypkg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the first 5 reviews\n",
        "\n",
        "documents_raw[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N0HbRw5vy4Ho",
        "outputId": "c3788ac2-fcfc-41e4-c142-e45d6d08d5e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('plot : two teen couples go to a church party , drink and then drive . \\nthey get into an accident . \\none of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \\nwhat\\'s the deal ? \\nwatch the movie and \" sorta \" find out . . . \\ncritique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \\nwhich is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway & memento ) , but there are good and bad ways of making all types of films , and these folks just didn\\'t snag this one correctly . \\nthey seem to have taken this pretty neat concept , but executed it terribly . \\nso what are the problems with the movie ? \\nwell , its main problem is that it\\'s simply too jumbled . \\nit starts off \" normal \" but then downshifts into this \" fantasy \" world in which you , as an audience member , have no idea what\\'s going on . \\nthere are dreams , there are characters coming back from the dead , there are others who look like the dead , there are strange apparitions , there are disappearances , there are a looooot of chase scenes , there are tons of weird things that happen , and most of it is simply not explained . \\nnow i personally don\\'t mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film\\'s biggest problem . \\nit\\'s obviously got this big secret to hide , but it seems to want to hide it completely until its final five minutes . \\nand do they make things entertaining , thrilling or even engaging , in the meantime ? \\nnot really . \\nthe sad part is that the arrow and i both dig on flicks like this , so we actually figured most of it out by the half-way point , so all of the strangeness after that did start to make a little bit of sense , but it still didn\\'t the make the film all that more entertaining . \\ni guess the bottom line with movies like this is that you should always make sure that the audience is \" into it \" even before they are given the secret password to enter your world of understanding . \\ni mean , showing melissa sagemiller running away from visions for about 20 minutes throughout the movie is just plain lazy ! ! \\nokay , we get it . . . there \\nare people chasing her and we don\\'t know who they are . \\ndo we really need to see it over and over again ? \\nhow about giving us different scenes offering further insight into all of the strangeness going down in the movie ? \\napparently , the studio took this film away from its director and chopped it up themselves , and it shows . \\nthere might\\'ve been a pretty decent teen mind-fuck movie in here somewhere , but i guess \" the suits \" decided that turning it into a music video with little edge , would make more sense . \\nthe actors are pretty good for the most part , although wes bentley just seemed to be playing the exact same character that he did in american beauty , only in a new neighborhood . \\nbut my biggest kudos go out to sagemiller , who holds her own throughout the entire film , and actually has you feeling her character\\'s unraveling . \\noverall , the film doesn\\'t stick because it doesn\\'t entertain , it\\'s confusing , it rarely excites and it feels pretty redundant for most of its runtime , despite a pretty cool ending and explanation to all of the craziness that came before it . \\noh , and by the way , this is not a horror or teen slasher flick . . . it\\'s \\njust packaged to look that way because someone is apparently assuming that the genre is still hot with the kids . \\nit also wrapped production two years ago and has been sitting on the shelves ever since . \\nwhatever . . . skip \\nit ! \\nwhere\\'s joblo coming from ? \\na nightmare of elm street 3 ( 7/10 ) - blair witch 2 ( 7/10 ) - the crow ( 9/10 ) - the crow : salvation ( 4/10 ) - lost highway ( 10/10 ) - memento ( 10/10 ) - the others ( 9/10 ) - stir of echoes ( 8/10 ) \\n',\n",
              "  'neg'),\n",
              " ('the happy bastard\\'s quick movie review \\ndamn that y2k bug . \\nit\\'s got a head start in this movie starring jamie lee curtis and another baldwin brother ( william this time ) in a story regarding a crew of a tugboat that comes across a deserted russian tech ship that has a strangeness to it when they kick the power back on . \\nlittle do they know the power within . . . \\ngoing for the gore and bringing on a few action sequences here and there , virus still feels very empty , like a movie going for all flash and no substance . \\nwe don\\'t know why the crew was really out in the middle of nowhere , we don\\'t know the origin of what took over the ship ( just that a big pink flashy thing hit the mir ) , and , of course , we don\\'t know why donald sutherland is stumbling around drunkenly throughout . \\nhere , it\\'s just \" hey , let\\'s chase these people around with some robots \" . \\nthe acting is below average , even from the likes of curtis . \\nyou\\'re more likely to get a kick out of her work in halloween h20 . \\nsutherland is wasted and baldwin , well , he\\'s acting like a baldwin , of course . \\nthe real star here are stan winston\\'s robot design , some schnazzy cgi , and the occasional good gore shot , like picking into someone\\'s brain . \\nso , if robots and body parts really turn you on , here\\'s your movie . \\notherwise , it\\'s pretty much a sunken ship of a movie . \\n',\n",
              "  'neg'),\n",
              " (\"it is movies like these that make a jaded movie viewer thankful for the invention of the timex indiglo watch . \\nbased on the late 1960's television show by the same name , the mod squad tells the tale of three reformed criminals under the employ of the police to go undercover . \\nhowever , things go wrong as evidence gets stolen and they are immediately under suspicion . \\nof course , the ads make it seem like so much more . \\nquick cuts , cool music , claire dane's nice hair and cute outfits , car chases , stuff blowing up , and the like . \\nsounds like a cool movie , does it not ? \\nafter the first fifteen minutes , it quickly becomes apparent that it is not . \\nthe mod squad is certainly a slick looking production , complete with nice hair and costumes , but that simply isn't enough . \\nthe film is best described as a cross between an hour-long cop show and a music video , both stretched out into the span of an hour and a half . \\nand with it comes every single clich ? . \\nit doesn't really matter that the film is based on a television show , as most of the plot elements have been recycled from everything we've already seen . \\nthe characters and acting is nothing spectacular , sometimes even bordering on wooden . \\nclaire danes and omar epps deliver their lines as if they are bored , which really transfers onto the audience . \\nthe only one to escape relatively unscathed is giovanni ribisi , who plays the resident crazy man , ultimately being the only thing worth watching . \\nunfortunately , even he's not enough to save this convoluted mess , as all the characters don't do much apart from occupying screen time . \\nwith the young cast , cool clothes , nice hair , and hip soundtrack , it appears that the film is geared towards the teenage mindset . \\ndespite an american 'r' rating ( which the content does not justify ) , the film is way too juvenile for the older mindset . \\ninformation on the characters is literally spoon-fed to the audience ( would it be that hard to show us instead of telling us ? ) , dialogue is poorly written , and the plot is extremely predictable . \\nthe way the film progresses , you likely won't even care if the heroes are in any jeopardy , because you'll know they aren't . \\nbasing the show on a 1960's television show that nobody remembers is of questionable wisdom , especially when one considers the target audience and the fact that the number of memorable films based on television shows can be counted on one hand ( even one that's missing a finger or two ) . \\nthe number of times that i checked my watch ( six ) is a clear indication that this film is not one of them . \\nit is clear that the film is nothing more than an attempt to cash in on the teenage spending dollar , judging from the rash of really awful teen-flicks that we've been seeing as of late . \\navoid this film at all costs . \\n\",\n",
              "  'neg'),\n",
              " (' \" quest for camelot \" is warner bros . \\' first feature-length , fully-animated attempt to steal clout from disney\\'s cartoon empire , but the mouse has no reason to be worried . \\nthe only other recent challenger to their throne was last fall\\'s promising , if flawed , 20th century fox production \" anastasia , \" but disney\\'s \" hercules , \" with its lively cast and colorful palate , had her beat hands-down when it came time to crown 1997\\'s best piece of animation . \\nthis year , it\\'s no contest , as \" quest for camelot \" is pretty much dead on arrival . \\neven the magic kingdom at its most mediocre -- that\\'d be \" pocahontas \" for those of you keeping score -- isn\\'t nearly as dull as this . \\nthe story revolves around the adventures of free-spirited kayley ( voiced by jessalyn gilsig ) , the early-teen daughter of a belated knight from king arthur\\'s round table . \\nkayley\\'s only dream is to follow in her father\\'s footsteps , and she gets her chance when evil warlord ruber ( gary oldman ) , an ex-round table member-gone-bad , steals arthur\\'s magical sword excalibur and accidentally loses it in a dangerous , booby-trapped forest . \\nwith the help of hunky , blind timberland-dweller garrett ( carey elwes ) and a two-headed dragon ( eric idle and don rickles ) that\\'s always arguing with itself , kayley just might be able to break the medieval sexist mold and prove her worth as a fighter on arthur\\'s side . \\n \" quest for camelot \" is missing pure showmanship , an essential element if it\\'s ever expected to climb to the high ranks of disney . \\nthere\\'s nothing here that differentiates \" quest \" from something you\\'d see on any given saturday morning cartoon -- subpar animation , instantly forgettable songs , poorly-integrated computerized footage . \\n ( compare kayley and garrett\\'s run-in with the angry ogre to herc\\'s battle with the hydra . \\ni rest my case . ) \\neven the characters stink -- none of them are remotely interesting , so much that the film becomes a race to see which one can out-bland the others . \\nin the end , it\\'s a tie -- they all win . \\nthat dragon\\'s comedy shtick is awfully cloying , but at least it shows signs of a pulse . \\nat least fans of the early-\\'90s tgif television line-up will be thrilled to find jaleel \" urkel \" white and bronson \" balki \" pinchot sharing the same footage . \\na few scenes are nicely realized ( though i\\'m at a loss to recall enough to be specific ) , and the actors providing the voice talent are enthusiastic ( though most are paired up with singers who don\\'t sound a thing like them for their big musical moments -- jane seymour and celine dion ? ? ? ) . \\nbut one must strain through too much of this mess to find the good . \\naside from the fact that children will probably be as bored watching this as adults , \" quest for camelot \" \\'s most grievous error is its complete lack of personality . \\nand personality , we learn from this mess , goes a very long way . \\n',\n",
              "  'neg'),\n",
              " ('synopsis : a mentally unstable man undergoing psychotherapy saves a boy from a potentially fatal accident and then falls in love with the boy\\'s mother , a fledgling restauranteur . \\nunsuccessfully attempting to gain the woman\\'s favor , he takes pictures of her and kills a number of people in his way . \\ncomments : stalked is yet another in a seemingly endless string of spurned-psychos-getting-their-revenge type movies which are a stable category in the 1990s film industry , both theatrical and direct-to-video . \\ntheir proliferation may be due in part to the fact that they\\'re typically inexpensive to produce ( no special effects , no big name stars ) and serve as vehicles to flash nudity ( allowing them to frequent late-night cable television ) . \\nstalked wavers slightly from the norm in one respect : the psycho never actually has an affair ; on the contrary , he\\'s rejected rather quickly ( the psycho typically is an ex-lover , ex-wife , or ex-husband ) . \\nother than that , stalked is just another redundant entry doomed to collect dust on video shelves and viewed after midnight on cable . \\nstalked does not provide much suspense , though that is what it sets out to do . \\ninterspersed throughout the opening credits , for instance , a serious-sounding narrator spouts statistics about stalkers and ponders what may cause a man to stalk ( it\\'s implicitly implied that all stalkers are men ) while pictures of a boy are shown on the screen . \\nafter these credits , a snapshot of actor jay underwood appears . \\nthe narrator states that \" this is the story of daryl gleason \" and tells the audience that he is the stalker . \\nof course , really , this is the story of restauranteur brooke daniels . \\nif the movie was meant to be about daryl , then it should have been called stalker not stalked . \\nokay . so we know who the stalker is even before the movie starts ; no guesswork required . \\nstalked proceeds , then , as it begins : obvious , obvious , obvious . \\nthe opening sequence , contrived quite a bit , brings daryl and brooke ( the victim ) together . \\ndaryl obsesses over brooke , follows her around , and tries to woo her . \\nultimately rejected by her , his plans become more and more desperate and elaborate . \\nthese plans include the all-time , psycho-in-love , cliche : the murdered pet . \\nfor some reason , this genre\\'s films require a dead pet to be found by the victim stalked . \\nstalked is no exception ( it\\'s a cat this time -- found in the shower ) . \\nevents like these lead to the inevitable showdown between stalker and stalked , where only one survives ( guess who it invariably always is and you\\'ll guess the conclusion to this turkey ) . \\nstalked\\'s cast is uniformly adequate : not anything to write home about but also not all that bad either . \\njay underwood , as the stalker , turns toward melodrama a bit too much . \\nhe overdoes it , in other words , but he still manages to be creepy enough to pass as the type of stalker the story demands . \\nmaryam d\\'abo , about the only actor close to being a star here ( she played the bond chick in the living daylights ) , is equally adequate as the \" stalked \" of the title , even though she seems too ditzy at times to be a strong , independent business-owner . \\nbrooke ( d\\'abo ) needs to be ditzy , however , for the plot to proceed . \\ntoward the end , for example , brooke has her suspicions about daryl . \\nto ensure he won\\'t use it as another excuse to see her , brooke decides to return a toolbox he had left at her place to his house . \\ndoes she just leave the toolbox at the door when no one answers ? \\nof course not . \\nshe tries the door , opens it , and wanders around the house . \\nwhen daryl returns , he enters the house , of course , so our heroine is in danger . \\nsomehow , even though her car is parked at the front of the house , right by the front door , daryl is oblivious to her presence inside . \\nthe whole episode places an incredible strain on the audience\\'s suspension of disbelief and questions the validity of either character\\'s intelligence . \\nstalked receives two stars because , even though it is highly derivative and somewhat boring , it is not so bad that it cannot be watched . \\nrated r mostly for several murder scenes and brief nudity in a strip bar , it is not as offensive as many other thrillers in this genre are . \\nif you\\'re in the mood for a good suspense film , though , stake out something else . \\n',\n",
              "  'neg')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffling since first 5 are 'neg'\n",
        "import random\n",
        "random.shuffle(documents_raw)"
      ],
      "metadata": {
        "id": "AD30J_7YGQ0T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents_raw[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GF8N-yhaGbdJ",
        "outputId": "ccbef23f-f631-4ba9-809f-93857575de36"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('an 18-foot-high , 43-foot-long dragon is the computer-generated co- star of this strictly-by-the-numbers sword \\'n\\' sorcery flick . \\nas voiced by sean connery , \" draco \" is a surprisingly expressive creation who is well-deserving of his 23 minutes of screen time . \\nhe walks , talks , flies , fries , and even fakes his own death , all with the help of 96 computer-aided animators . \\ntoo bad that ilm ( industrial light and magic ) couldn\\'t spare some special effects for dragonheart\\'s * human * co-stars . \\na bearded black hole exists where dennis quaid should be . \\nhe\\'s a near-total loss as he growls glumly through his role of a disillusioned knight . \\ndavid thewlis\\' evil king has a high hiss factor ( hf ) , though he\\'s more of a mumbling oddity than anything else . \\noh , and there\\'s some redhead in a \\'90\\'s wig , who runs around either screaming or scowling , depending upon if the particular scene has her playing the woman in peril or the put upon peasant . \\nthe fringe flourishes include pete postlethwaite as a wandering monk with literary ambitions , julie christie ( ! ) as the good queen mother , a band of mercenaries that appear dressed for ye olde heavy-metal concert , and , believe or it not , the speaking spirit of king arthur . \\nbring out your dead ! \\nunfortunately , when we add it all together ( draco + fringe bits - quaid - thewlis ) , the sum total amounts to zero . \\ndragonheart is , well , too much of too little . \\ndirector rob cohen ( dragon : the bruce lee story ) has made a big , expensive movie that , while ambitiously plotted , is both murky and predictable . \\nand overscored . \\nand self-important . \\nand the list goes on . \\n ( i must ask : did screenwriter charles edward pogue intend that * every * character be stabbed , lanced , or sliced at least once ? \\nkeep that man away from the knife drawer ! ) \\nthe last five minutes of this movie are the worst , with some silly celestial nonsense that would be laughed out of any planetarium light show , much less a summer movie . \\nsave your money . \\n',\n",
              "  'neg'),\n",
              " ('i find most of television so intensely boring that i simply never turn on my set , unless i\\'m watching a movie . \\ni don\\'t even have cable , so i went to radio shack to buy an antenna specifically for the purpose of watching \" the x-files \" every sunday night . \\nit\\'s the only show that\\'s worth an hour of my time each week ( though , since i don\\'t watch reruns , i\\'m glad that i have six months of the year to avoid television altogether ) . \\ni am an avid fan of the show , and have been for about three years now . \\nand i love gillian anderson . \\nthe x-files is the film that continues the story where the season finale left off . \\nthe film is like a two-hour episode , except that there are a lot more special effects , the plot is thicker , and the resolution is more satisfying . \\nthis is a terrific film , both for fans of the series and for those who have never seen it ( i imagine that viewers unfamiliar with the show will find the film to be solid and riveting entertainment ) . \\ni expected to like it more than any episode i\\'ve seen , and my expectations were met . \\nactually , the film takes a few risks in its story and plot devices , but , thankfully , the makers managed to do it right . \\nwhen the finale ended , the fbi branch known as the x-files had been destroyed , and our heroes , mulder ( david duchovny ) and scully ( gillian anderson ) were left stripped of five years of hard work . \\nthe film picks up soon after ; and mulder and scully have been reduced to field agents investigating a bomb threat in a federal building . \\nbut wait , i\\'m getting ahead of myself . \\nthe film actually opens in the ice age , about 32 , 000 years prior , during which a couple of prehistoric guys get attacked by a vicious alien . \\nthe alien\\'s blood infects them ( fans of the show will certainly remember the black cancer ) , and the story jumps into modern times , during which a young boy is also infected with the cancer . \\nit turns out that the bomb was planted to kill the boy , and mulder and scully uncover the cover-up despite the fact that scully has resigned from her position in the fbi . \\nsoon , they find out that the whole thing has to do with aliens . \\nas i\\'ve written before , it\\'s not easy to write plot summaries for films like this , because everything needs to be a surprise . \\nfans of the show will know what to expect , and i seriously doubt any of them being disappointed with the film . \\ndirector rob bowman has done a great job expanding the eerie feeling of the show to the big screen , making small adjustments and minor changes to utilize the possibilities that film allows over television . \\nthere are some truly suspenseful and well-created scenes here ( late in the film , when they\\'re in the alien spacecraft , you\\'ll see one of the better action sequences in recent cinema ) . \\nthe special effects are very good , and the production design by christopher nowak is fantastic . \\nwhat i find interesting is that the x-files is actually a great way for series neophytes to get into the story . \\nour heroes are given subtle introductions ( we\\'re not expected to know them on the outset ) , and the film explains enough of the story that prior knowledge of the series isn\\'t required to understand the film . \\nthere are , of course , little elements that the makers have included as payoff to the fans , but i\\'ll keep those as surprises . \\nit takes a lot of thought and understanding of the series to create a film using roots as complicated as the ones that the series provides , and then create a coherent film that anyone can understand clearly . \\nthe series is strong for a lot of reasons . \\nit\\'s original ( though it has many ties to \" the twilight zone \" and owes some homage to hitchcock ) , and impressively eerie for a television show . \\nwhat really makes the series shine , however , are the actors . \\nduchovny has so much presence , and is just a fun guy to watch . \\nhe has that confidence that will someday make him into a bankable leading man . \\nanderson is equally good , and paralyzingly beautiful ; she\\'s also a strong actress . \\nboth performers have acted in little more than their series , however , though i think they\\'ll both get their chances to prove themselves very soon . \\ni enthusiastically recommend the x-files , both for fans and non-fans . \\n1998 is a summer filled with disappointing blockbusters , and this film should satisfy where most of the others leave you completely dry . \\nit\\'s an intelligent film , and takes you places that you might not have been ( or , at least , might not have seen so many times that they feel familiar ) . \\nthe x-files is impressive in concept , as well : fans of the series are likely to be highly critical , and to take the premise beyond the series is a risky move . \\nit\\'s nice to see a risk pay off for a change . \\nactually , it\\'s nice to see a risk at all . \\n',\n",
              "  'pos'),\n",
              " (\"kevin smith is like a big kid . \\nhis humor is that of a sophisticated juvenile's . \\nhe grew up idolizing star wars and loves comic books , having also written a few . \\nhe also has a cult following , mostly composed of teenagers , college students , and smith's own fellow adolescent-minded grownups . \\nsmith is hilarious in person and in writing , but when he tries to be earnest and moralize , that is when he goes wrong . \\nkevin smith is a better writer than director , and he'll be the first to tell you that . \\nthat might also be part of the reason why his moralizing comes across as so heavy-handed . \\ngreat directors show us their theses instead of having the characters sermonize them . \\nthis was true in the overrated chasing amy , and it is true for dogma as well . \\nthat is not to say smith's message is a bad one . \\nin dogma , smith tells us that problems arise when people believe beyond any doubt that their insight into god and god's desires is superior to anyone else's . \\nbasically , dogmatism is bad . \\nchanging the minds of the dogmatic is virtually impossible , and since the dogmatic believe that they have special insight , they also know what is best for you , whether you like it or not . \\nthis is not exactly a new message in movies ( see inherit the wind ) , but i have no problems with recycling old ones , particularly since dogma's protesters are proving smith's point . \\nsmith's own problem with delivering this message is that he beats us over the head with it like we are reading a dogma for dummies book . \\nbut this is smith's personality , and his simplistic views neglect such adult issues as how does one interpret the bible ( or koran , etc . ) correctly ( or if there even is a correctly ) and how one settles disputes of heretofore dogmatic concerns . \\nthe story concerns abortion clinic worker bethany ( linda fiorentino ) being chosen by voice of god , metatron ( alan rickman ) , to prevent the destruction of the universe by two fallen angels , bartleby ( ben affleck ) and angel of death , loki ( matt damon ) . \\nalong the way , forgotten thirteenth apostle , rufus ( chris rock ) , stripper muse serendipity ( salma hayek ) , and slacker duo jay and silent bob ( jason mewes and kevin smith himself ) come to bethany's aid . \\nfallen muse , azrael ( jason lee ) , proves to be the behind-the-scenes manipulator for all the chicanery . \\nthe logical but convoluted plot only exists as an excuse for the jokes and to make smith's points , and in itself , has little dramatic momentum . \\namong the supposedly outrageous claims made by the film is that god is a woman , jesus was black , and the bible was written by a bunch of racist , misogynistic white men . \\nof course , kevin smith does not necessarily subscribe to these ideas himself . \\nthey are a metaphor for the fears and insecurities of the dogmatic . \\nsmith says as much in his amusing disclaimer that precedes the movie . \\nwhen harvey weinstein asked smith to put it into the film before cannes , smith thought it might give validation to protesters' claims that the film was sacrilegious , but then he rethought it and turned the disclaimer into a joke . \\nthe film's humor is uneven . \\nsome parts are very funny as when bethany goes for a fire extinguisher when metatron makes a burning-bush kind of entrance . \\nbut many of the film's jokes just bomb , as in virtually anything involving salma hayek's serendipity . \\nalso , some of the jokes can be seen coming from a mile away . \\nstill , smith keeps the zingers coming at a sufficiently rapid pace . \\namong the actors , fiorentino and rickman stand out by far . \\nfiorentino virtually by herself gives the film emotional weight . \\ndamon and affleck are fairly lackluster . \\nrock and hayek exist in the film pretty much only as comic relief as are mews and smith . \\nbut the latter duo fare much better because jay and silent bob , who recur in all of smith's movies , are much more in line with smith's brand of humor . \\nbud cort , george carlin , janeane garofalo , guinevere turner , and alanis morissette all make cameo appearances . \\n\",\n",
              "  'pos'),\n",
              " ('warning : spoilers are included in this review . . . \\nbut it doesn\\'t really make much of a difference . \\ndeep impact begins the official summer movie season , and it also brings back memories of 1997 . \\nremember when dante\\'s peak came out in february ? \\na few months later , volcano was released . \\nthe first film was smart , exhilirating , and one of the best disaster films i had ever seen . \\nthe latter film was an incohesive mess that defied logic and wasted talent . \\nwell , it\\'s deja vu all over again as two disaster films go head to head in competition . \\nthis time , unfortunately , the first comet flick is so bad that people may shy away from armageddon , the upcoming comet-disaster to be released the beginning of july . \\nof course , the general reaction of the audience was oppposed to mine , and so i am in the minority , as i was when i stood on the side of dante\\'s peak . \\nbut while watching deep impact , i began to wonder how anyone in their right mind could actually like this film . \\napparently many did , and it utterly baffles me . \\nto be completely honest , i haven\\'t had this little fun watching a disaster film in my entire life . \\nvolcano had implausibilities up the wazoo , but it was still rather fun to watch . \\ndeep impact doesn\\'t just have implausibilities , it also contains cheap human drama , incredibly horrible special effects , and a poorly constructed plot . \\nthe only thing that gives it a half star above my bottom ranking is a slightly entertaining final fifteen minutes and some good actors making the most of their characters . \\ndeep impact begins in an unnamed year ( the year varies ; advanced technology sets it in the future , but fire in the sky is showing on a local movie theater , pushing it back to 1993 ) . \\na line of students is outside at night , peering through telescopes at the dark sky above . \\namong these are leo biederman ( elijah wood ) and sarah hotchner ( leelee sobieski ) . \\nleo unknowingly discovers a comet , and his teacher sends a photo of the unknown object to an astronomer , who then is able to determine the correct path of this distant comet in about a few seconds . \\nhe races off to mail the information , but is killed in a reckless car accident . \\na year passes , and nothing is heard about it again . \\nwe are then introduced to jenny lerner ( t ? a leoni ) , a reporter for msnbc . \\nshe gets handed a job to investigate a possible cover-up in the government involving senator alan rittenhouse ( james cromwell ) . \\nshe talks to a woman who mentions that rittenhouse was having an affair with a girl named ellie . \\nafter talking with rittenhouse , and unsatisfied with the information she gets , she decides to use the internet for help . \\nluckily , she knows exactly how to spell the certain \" ellie \" that she is looking for ( they spell it ele in the film . . . \\nthat girl is pretty darn smart for guessing how it was spelled ) . \\nbefore she can use the information , the government decides to push her car off the road . \\nthey take her in to meet the president of the united states , president beck ( morgan freeman ) . \\nbeck recommends that jenny keep the information secret for 48 hours so they can confirm it and then hold a press conference . \\nnaturally , she wants to be compensated , and they offer her a front row seat and the chance for the first question . \\nand so , yada yada yada , they reveal the comet to the public and their plans : send a massive spacecraft out to destroy it before it can arrive . \\nthey announce a plan called \" ark , \" which is their only hope for survival . \\na computer will select 800 , 000 people at random . \\nthese people are the ones who will go into a large cave underground so that the impact of the comet won\\'t kill off the entire human race . \\nafter two years , the dust will settle ( actually , it would take much , much longer--approximately ninety years , from what i understand ) and the humans could come back to the surface and start over . \\nthe rest of the plot is your standard disaster film procedures , but there is one subplot worth mentioning . \\njenny and her father , jason ( maximilian schell ) , have a very touching relationship that forms out of the impending doom . \\nthe final moment involving the two characters is heartfelt and emotional . \\nit\\'s a shame that nothing else is heartfelt . \\nnow , of course , we all know that the comet does impact the surface . \\nthe title alone suggests it , and the previews actually show it ! \\nby doing this , absoltuely no tension can be drawn from any attempt to stop the comet because we all know that it won\\'t work . \\ndirector mimi leder came from her successful tries at direction with episodes of the hit television show \" er . \" \\nher major film debut was the peacemaker , a pathetic and heartless action film . \\nwell , this time leder outdid herself , creating a film worse than that one . \\nsuggestion to ms . leder : please , stay away from the big screen , or at least the action genre . \\nmuch of the blame can be placed on leder directly , because the pace is disastrously off . \\nthroughout the film we are given subtitles that tell us how much time has passed ( it goes from months to weeks to hours ) . \\nit literally feels like this lapsed time is taking place in real-time--it\\'s that boring . \\nof course , leder isn\\'t all to blame for it . \\nscreenwriters michael tolkin and bruce joel rubin have crafted a simplistic story that only gets worse with time . \\nwhat starts out promising soon turns deadly ( for the audience anyway ) . \\nchock full of cheesy one liners ( \" you know , you are going to have more sex than anyone else in school ! \" ) \\nand stupid characters , you might think we were back in the 70s again . \\nonly one of the subplots is remotely interesting , while the rest are forgettable and boring . \\nand the main plot is so outrageous that you can\\'t figure out if this film is supposed to be an action , drama , or sci-fi . \\nto put it simply : the special effects of this film are a hit and miss situation . \\nthat\\'s right , 80% miss , and 20% hit . \\nscenes above the earth are well done , and the orbiting ship is majestic . \\nbut the comet is a huge mistake , making it more laughable than frightening . \\nthe concept of even trying to land on a comet is preposterous enough , but that\\'s forgiveable . \\nwhat isn\\'t forgiveable is actually having humans walk on the surface . \\ngive me a break , will ya ? \\nand of course , the much hyped collision of comet and earth . \\nwell , it is far from spectacular , and it makes independence day look brilliant . \\nthe water rushing towards the land is effective , but once it hits the continent , the effects turn ridiculous . \\ncgi water is used , and it looks so bad that i heard more laughs from the audience than shrieks . \\nin fact , i may even recommend the film for those who want to see how bad effects can actually get these days . \\njust when we think visual effects can\\'t be improved , along comes a film to show that they really can and should be . \\none thing has struck a wrong note with me concerning mimi leder\\'s direction , which also influences the actors . \\nleder loves to show the actors\\' faces before and during moments of terror . \\nthis reminded me of another action director , renny harlin ( die hard 2 , cliffhanger ) . \\nbut harlin succeeds because he shows the faces of the victims in realistic situations . \\nleder likes to flaunt people\\'s fears via their faces , but instead of coming off as sympathetic , leder seems more of a sadist . \\none moment has an astronaut flying off into space . \\nthis should be enough to warrant a response from the audience , but leder wants to go farther and shows us the person\\'s face while drifting into space . \\nthis is one of the cheapest ways to ellicit an emotional response from an audience , and i , for one , am not going to be fooled . \\non another note , leder\\'s film only picks up its pace during the last fifteen minutes when the comet actually impacts . \\nthe pace does pick up , and some very emotional moments are shown . \\nthen again , when you watch people cry for their loved ones , it\\'s obvious it will be emotional . \\nit\\'s mostly just a big trick to rope viewers into \" feeling \" for the characters , but it didn\\'t work for me . \\nbut anyway , the actors do as much as they can with what they are given . \\nt ? a leoni ( bad boys , tv\\'s \" the naked truth \" ) is the best of the film , and she is given the meatiest role . \\nher character is made stronger by leoni\\'s presence , and we grow to care for her . \\nrobert duvall is energetic and fun to watch , but his character is turned into shreds by the plot . \\nelijah wood also comes off rather successfully , but he still hasn\\'t had many good roles ( wood , stick to drama ! \\nyou are too talented for this stuff ) . \\nvanessa redgrave is barely acknowledgeable , and her performance is only enhanced by her strong presence on screen . \\nmaximilian schell is distracting , but he does provide some nice humor . \\nmorgan freeman has been infinitely better than this , and gives one of his most shallow performances to date ( which is quite remarkable for him ) . \\nleelee sobieski could have been better , but i think she just suffered from a poorly written character . \\na special note should go to ron eldard and denise crosby . \\neldard is good in his role , but is limited by the plot . \\ncrosby is special to me personally because she was tasha yar from tv\\'s \" star trek : the next generation . \" \\nseeing her was one of the highlights of the film . \\noverall , a very talented cast virtually wasted . \\ndeep impact is rated pg-13 for disaster related elements and brief language . \\nthis is one of the worst films of the year , and if it is any omen of things to come , this summer could be one of the worst ever . \\nluckily , the x-files movie is coming up , and hopefully armageddon will be more successful . \\nit\\'s a shame that this film will do so successfully because it just isn\\'t worth much . \\ncosting nearly $75 million , with special effects done by the illustrious ilm ( which is a huge shocker ) , and with a score composed by oscar-winner james horner ( titanic ) , one might have expected this to be more fun to witness and experience . \\nwell , it\\'s not . \\nwhen the comet does hit the earth , you almost wish it could just take this film along with it . \\n',\n",
              "  'neg'),\n",
              " (\"capsule : five friends at a stag party are involved in the accidental killing of a prostitute . \\nthe cover-up attempt becomes a monster that eats up the friends , two wives and several innocent bystanders . \\nthis was a real audience pleaser at toronto , but it did not do much for me . \\n , low 0 ( -4 to +4 ) \\n- directed by peter berg who acted in the last seduction and copland . \\n- five buddies go on a stag outing to las vegas while cameron diaz works through the logistics of her upcoming wedding to one of them . \\none of the buddies accidentally kills a prostitute . \\n- several people with no moral compass . \\nthey started out with a simple , innocent little cocaine party ( ! ) and by accident look what happened . \\nthey have one moral person among them ( daniel stern ) , and one totally amoral person ( christian slater ) . \\nit is more selfish to let the amoral lead , so they do . \\n- this film is strange , but not really funny or biting . \\nblack comedy should actually be funny as well as strange . \\nthere should be some element of satire . \\nthe satire is missing here . \\ni did not find myself laughing here either . \\nwhat we have is a strange crime tale . \\n- one just does not care what happens to these people . \\n- the same idea of people just getting themselves in deeper and deeper has been done frequently . \\nif this film is popular it is just bringing a familiar plot to a new generation . \\n- it begins like diner ( particularly with daniel stern ) and ends up like an extended horror/crime comic book . \\n- there are several logical holes in script . \\nif a security man goes to investigate a complaint and disappears , wouldn't the guests he was investigating be the first suspects ? \\nsomeone framed for a crime in the way shown would be judged innocent after minimal forensic detective work . \\n ( i am desperately trying to avoid making this a spoiler . ) \\n- popular and situation ethics get a real slamming . \\n- some acting of grief is hammy and overdone . \\nmore yelling than humor . \\n\",\n",
              "  'neg')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the movie_reviews dataset\n",
        "# Iterate over categories, iterate over every document in each category,\n",
        "# create a list of tuples ([tokens for reviews], [category name of reviews])\n",
        "\n",
        "documents = [(movie_reviews.words(fileid), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]"
      ],
      "metadata": {
        "id": "Ftz01NVugGft"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "import contractions\n",
        "import emoji\n",
        "from nltk.sentiment.util import mark_negation\n",
        "from nltk import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvxpzL5Dx_IA",
        "outputId": "429fcff4-d3c6-412c-91cc-7e5fef288677"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "\n",
        "STOP = set(stopwords.words('english'))\n",
        "LEMMAT = WordNetLemmatizer()\n",
        "PUNCT = set(string.punctuation)\n",
        "\n",
        "def preprocess(words):\n",
        "    # contractions - don't to do not\n",
        "    tokens = [contractions.fix(w) for w in words]\n",
        "    # lowercase\n",
        "    tokens = [w.lower() for w in tokens]\n",
        "    # convert emoji to tect\n",
        "    tokens = [emoji.demojize(w) for w in tokens]\n",
        "    # remove punctuation-only tokens\n",
        "    tokens = [w for w in tokens if not (all(ch in string.punctuation for ch in w) and w not in {'!', '?', '/'})]\n",
        "    # lemmatize\n",
        "    tokens = [LEMMAT.lemmatize(w) for w in tokens]\n",
        "    # Negation Marking\n",
        "    tokens = mark_negation(tokens) # can be improved to only tag sentiments (adjectives and verbs)\n",
        "    # remove stopwords\n",
        "    tokens = [w for w in tokens if w not in STOP]\n",
        "    return tokens\n",
        "\n",
        "#can also add tokeniser here instead of breaking the reviews into words - need to check which is better - words or default token library"
      ],
      "metadata": {
        "id": "u4o-UglN084m"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction**"
      ],
      "metadata": {
        "id": "nSBgNbeXku7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "docs = [' '.join(movie_reviews.words(feild)) for feild in movie_reviews.fileids()]\n",
        "\n",
        "# Top 2000 unigrams\n",
        "all_words = nltk.FreqDist(word.lower() for word in movie_reviews.words())\n",
        "word_features = [word for word, _ in all_words.most_common(2000)]\n",
        "\n",
        "# Top 500 bigrams by likelihood ratio\n",
        "bigram_finder = BigramCollocationFinder.from_words(word.lower() for word in movie_reviews.words())\n",
        "bigram_features = bigram_finder.nbest(BigramAssocMeasures.likelihood_ratio, 500)\n",
        "\n",
        "# Top TF-IDF terms\n",
        "vectorizer = TfidfVectorizer(max_features=2000, stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "tfidf_features = vectorizer.get_feature_names_out()\n"
      ],
      "metadata": {
        "id": "d-QUDYRgmhQ9"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textstat\n",
        "from collections import Counter\n",
        "from nltk import bigrams, trigrams, pos_tag\n",
        "from textstat import syllable_count\n",
        "\n",
        "NEG_WORDS = {'not','never','no','nothing'}\n",
        "COMPARATIVE_TAGS = {'JJR'}    # comparitive adjectives: e.g. â€œbetterâ€\n",
        "SUPERLATIVE_TAGS = {'JJS'}    # superlative adjectives: e.g. â€œbestâ€\n",
        "DISCOURSE_MARKERS = {'however','although','instead','therefore', 'even though'}\n",
        "\n",
        "def features_tuning(tokens):\n",
        "    \"\"\"\n",
        "    tokens: list of preprocessed tokens (strings)\n",
        "    returns: dict of feature_name -> value\n",
        "    \"\"\"\n",
        "    features = {}\n",
        "    cnt = Counter(tokens)\n",
        "    token_set = set(tokens)\n",
        "    text = \" \".join(tokens)\n",
        "\n",
        "    # Bag-of-Words presence\n",
        "    for w in word_features:\n",
        "        features[f\"bow({w})\"] = (w in token_set)\n",
        "\n",
        "    # Bag-of-Bigrams presence\n",
        "    toks_bigrams = list(bigrams(tokens))\n",
        "    for bg in bigram_features:\n",
        "        features[f\"bigram({bg[0]}_{bg[1]})\"] = (bg in toks_bigrams)\n",
        "\n",
        "    # TFâ€“IDF top terms presence\n",
        "    for t in tfidf_features:\n",
        "        features[f\"tfidf({t})\"] = (t in token_set)\n",
        "\n",
        "    # Punctuation counts\n",
        "    features['exclaim_count']   = cnt['!']\n",
        "    features['question_count']  = cnt['?']\n",
        "\n",
        "    # â€œbutâ€ contrast\n",
        "    features['but_present'] = (cnt['but']>0)\n",
        "\n",
        "    # Comparatives & superlatives\n",
        "    tagged = pos_tag(tokens)\n",
        "    features['comparatives']  = sum(1 for _,pos in tagged if pos in COMPARATIVE_TAGS)\n",
        "    features['superlatives']  = sum(1 for _,pos in tagged if pos in SUPERLATIVE_TAGS)\n",
        "\n",
        "    # Discourse markers\n",
        "    for dm in DISCOURSE_MARKERS:\n",
        "        features[f\"disc_{dm}\"]   = (dm in token_set)\n",
        "        features['disc_even_though'] = ('even','though') in list(bigrams(tokens))\n",
        "\n",
        "    # Rhetorical questions\n",
        "    # count â€œwhy?â€ or â€œhow?â€ style occurrences\n",
        "    features['why_q']  = 'why' in tokens and cnt['?']>0\n",
        "    features['how_q']  = 'how' in tokens and cnt['?']>0\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "fk1yZ92v2ILU"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4\n",
        "4. Train a logistic regression-based classifier for classifying reviews. Consider the usual separation of training, test, and development set. (3 points)"
      ],
      "metadata": {
        "id": "LVUd2Xq0LsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents_raw = [(movie_reviews.raw(f), movie_reviews.categories(f)[0]) for f in movie_reviews.fileids()]\n",
        "\n",
        "# Extract text and categories into separate lists\n",
        "X = [review for review, category in documents_raw]\n",
        "y = [category for review, category in documents_raw]"
      ],
      "metadata": {
        "id": "u3LoMbjH3d1C"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# random.shuffle(documents)"
      ],
      "metadata": {
        "id": "yB_jui9W2nA1"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "IO-tH1nYy7_t"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting into train, test and development sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.80 = 0.20"
      ],
      "metadata": {
        "id": "OORbecJf16Eo"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TDG9ozMb3gh",
        "outputId": "c844b50f-3dc4-4a32-b521-b96a1f0bf6a1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess & featurize\n",
        "X_train_features = [features_tuning(preprocess(nltk.word_tokenize(str(doc)))) for doc in X_train]\n",
        "X_dev_features = [features_tuning(preprocess(nltk.word_tokenize(str(doc)))) for doc in X_dev]\n",
        "#X_test_features = [features_tuning(preprocess(nltk.word_tokenize(str(doc)))) for doc in X_test]"
      ],
      "metadata": {
        "id": "Xq4DZvlybTMl"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
        "\n",
        "dv    = DictVectorizer(sparse=True)\n",
        "X_tr   = dv.fit_transform(X_train_features)\n",
        "X_de   = dv.transform  (X_dev_features)\n",
        "#X_te   = dv.transform  (X_test_features)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_tr, y_train)\n",
        "\n",
        "clf.score(X_tr, y_train) # to check overfitting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqfZHz7D2QIE",
        "outputId": "8b949f44-73d6-4e4c-aeed-ca819e4059ee"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9908333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "722d0831",
        "outputId": "c2023a93-1e08-4acc-9810-c09468eef8f5"
      },
      "source": [
        "print(classification_report(y_dev, clf.predict(X_de)))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.67      0.71      0.69       199\n",
            "         pos       0.70      0.65      0.67       201\n",
            "\n",
            "    accuracy                           0.68       400\n",
            "   macro avg       0.68      0.68      0.68       400\n",
            "weighted avg       0.68      0.68      0.68       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tune hyperparamenters and fixing preprocessing step\n",
        "\n",
        "# Preprocessing\n",
        "\n",
        "STOP = set(stopwords.words('english'))\n",
        "LEMMAT = WordNetLemmatizer()\n",
        "PUNCT = set(string.punctuation)\n",
        "\n",
        "def preprocess(words):\n",
        "    # contractions - don't to do not\n",
        "    tokens = [contractions.fix(w) for w in words]\n",
        "    # lowercase\n",
        "    tokens = [w.lower() for w in tokens]\n",
        "    # convert emoji to tect\n",
        "    tokens = [emoji.demojize(w) for w in tokens]\n",
        "    # remove punctuation-only tokens\n",
        "    tokens = [w for w in tokens if not (all(ch in string.punctuation for ch in w) and w not in {'!', '?', '/'})]\n",
        "    # lemmatize\n",
        "    tokens = [LEMMAT.lemmatize(w) for w in tokens]\n",
        "    # Negation Marking\n",
        "    #tokens = mark_negation(tokens) # can be improved to only tag sentiments (adjectives and verbs) # removing this\n",
        "    # remove stopwords\n",
        "    tokens = [w for w in tokens if w not in STOP]\n",
        "    return tokens\n",
        "\n",
        "#can also add tokeniser here instead of breaking the reviews into words - need to check which is better - words or default token library"
      ],
      "metadata": {
        "id": "qx8sB7sCxdch"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textstat\n",
        "from collections import Counter\n",
        "from nltk import bigrams, trigrams, pos_tag\n",
        "from textstat import syllable_count\n",
        "\n",
        "NEG_WORDS = {'not','never','no','nothing'}\n",
        "COMPARATIVE_TAGS = {'JJR'}    # comparitive adjectives: e.g. â€œbetterâ€\n",
        "SUPERLATIVE_TAGS = {'JJS'}    # superlative adjectives: e.g. â€œbestâ€\n",
        "DISCOURSE_MARKERS = {'however','although','instead','therefore', 'even though'}\n",
        "\n",
        "def improved_features_tuning(tokens):\n",
        "    \"\"\"\n",
        "    tokens: list of preprocessed tokens (strings)\n",
        "    returns: dict of feature_name -> value\n",
        "    \"\"\"\n",
        "    features_improved = features_tuning(tokens)\n",
        "    #cnt = Counter(tokens)\n",
        "    #token_set = set(tokens)\n",
        "    #text = \" \".join(tokens)\n",
        "\n",
        "    # Count how many trigrams start with a NEG_WORD\n",
        "    neg_trigram_counts = Counter(\n",
        "        (w2, w3)\n",
        "        for (w1, w2, w3) in trigrams(tokens)\n",
        "        if w1 in NEG_WORDS\n",
        "    )\n",
        "    # count of all negation trigrams\n",
        "    features_improved['neg_trigram_total'] = sum(neg_trigram_counts.values())\n",
        "\n",
        "    return features_improved"
      ],
      "metadata": {
        "id": "TIDR1GcyYgrn"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess & featurize\n",
        "X_train_features = [improved_features_tuning(preprocess(nltk.word_tokenize(str(doc)))) for doc in X_train]\n",
        "X_dev_features = [improved_features_tuning(preprocess(nltk.word_tokenize(str(doc)))) for doc in X_dev]\n",
        "X_test_features = [improved_features_tuning(preprocess(nltk.word_tokenize(str(doc)))) for doc in X_test]"
      ],
      "metadata": {
        "id": "MDwNGUE2fc3W"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.feature_extraction import DictVectorizer\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
        "\n",
        "dv    = DictVectorizer(sparse=True)\n",
        "X_tr   = dv.fit_transform(X_train_features)\n",
        "X_de   = dv.transform  (X_dev_features)\n",
        "X_te   = dv.transform  (X_test_features)\n",
        "\n",
        "#clf = LogisticRegression(max_iter=1000)\n",
        "#clf.fit(X_tr, y_train)\n",
        "\n",
        "#clf.score(X_tr, y_train) # to check overfitting"
      ],
      "metadata": {
        "id": "zFmIatMBfinu"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine features & labels\n",
        "X_full_feats = X_train_features + X_dev_features\n",
        "y_full       = list(y_train) + list(y_dev)\n",
        "\n",
        "# vectorize\n",
        "X_full = dv.fit_transform(X_full_feats)\n",
        "\n",
        "# fit final\n",
        "clf_final = LogisticRegression(max_iter=1000)\n",
        "clf_final.fit(X_full, y_full)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Rhqt7DOYhdKM",
        "outputId": "b11e90c9-a591-4ca8-a04e-3917a403c795"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f39a74ca",
        "outputId": "3760f927-5962-4e8e-ff49-7fbef2c9d865"
      },
      "source": [
        "X_test = dv.transform(X_test_features)\n",
        "y_pred = clf_final.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.81      0.79      0.80       199\n",
            "         pos       0.80      0.82      0.81       201\n",
            "\n",
            "    accuracy                           0.81       400\n",
            "   macro avg       0.81      0.80      0.80       400\n",
            "weighted avg       0.81      0.81      0.80       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 6"
      ],
      "metadata": {
        "id": "4Q36_k-XNoq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "metadata": {
        "id": "AEG5H-WYFp0E"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j_jVpHiAVJe",
        "outputId": "eecb29bf-2740-4e39-f9c8-6afb5d3c4af9"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1200"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=2000, stop_words='english')\n",
        "dv = DictVectorizer(sparse=True)\n",
        "X_train_counts = dv.fit_transform(X_train_features)\n",
        "X_test_counts = dv.transform(X_test_features)\n",
        "\n",
        "# 3) Extract the feature names (these are your â€œvocabularyâ€ of handcrafted features)\n",
        "feature_names = dv.get_feature_names_out()\n",
        "\n",
        "# 4) Fit the tfâ€“idf transformer on the TRAINING counts\n",
        "tfidf_tr      = TfidfTransformer(norm=None)          # norm=None keeps raw tfâ€“idf\n",
        "X_train_tfidf    = tfidf_tr.fit_transform(X_train_counts)  # learns IDF from training data\n",
        "\n",
        "# 5) Transform the TEST counts into tfâ€“idf\n",
        "X_test_tfidf  = tfidf_tr.transform(X_test_counts)\n",
        "\n",
        "# 6) Build a DataFrame for the TRAINING tfâ€“idf matrix\n",
        "df_tfidf_train = pd.DataFrame(X_train_tfidf.toarray(), columns = feature_names)\n",
        "df_tfidf_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "_xOQvzAW-3Ua",
        "outputId": "dffd4d42-1311-40bc-e231-b246bf3c8245"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      bigram(!_!)  bigram(!_\")  bigram(!_))  bigram(&_nbsp)  bigram('_')  \\\n",
              "0             0.0          0.0          0.0             0.0          0.0   \n",
              "1             0.0          0.0          0.0             0.0          0.0   \n",
              "2             0.0          0.0          0.0             0.0          0.0   \n",
              "3             0.0          0.0          0.0             0.0          0.0   \n",
              "4             0.0          0.0          0.0             0.0          0.0   \n",
              "...           ...          ...          ...             ...          ...   \n",
              "1195          0.0          0.0          0.0             0.0          0.0   \n",
              "1196          0.0          0.0          0.0             0.0          0.0   \n",
              "1197          0.0          0.0          0.0             0.0          0.0   \n",
              "1198          0.0          0.0          0.0             0.0          0.0   \n",
              "1199          0.0          0.0          0.0             0.0          0.0   \n",
              "\n",
              "      bigram('_,)  bigram('_.)  bigram('_a)  bigram('_and)  bigram('_d)  ...  \\\n",
              "0             0.0          0.0          0.0            0.0          0.0  ...   \n",
              "1             0.0          0.0          0.0            0.0          0.0  ...   \n",
              "2             0.0          0.0          0.0            0.0          0.0  ...   \n",
              "3             0.0          0.0          0.0            0.0          0.0  ...   \n",
              "4             0.0          0.0          0.0            0.0          0.0  ...   \n",
              "...           ...          ...          ...            ...          ...  ...   \n",
              "1195          0.0          0.0          0.0            0.0          0.0  ...   \n",
              "1196          0.0          0.0          0.0            0.0          0.0  ...   \n",
              "1197          0.0          0.0          0.0            0.0          0.0  ...   \n",
              "1198          0.0          0.0          0.0            0.0          0.0  ...   \n",
              "1199          0.0          0.0          0.0            0.0          0.0  ...   \n",
              "\n",
              "      tfidf(wrote)  tfidf(yeah)  tfidf(year)  tfidf(years)  tfidf(yes)  \\\n",
              "0              0.0          0.0          1.0           0.0         0.0   \n",
              "1              0.0          0.0          1.0           0.0         0.0   \n",
              "2              0.0          0.0          1.0           0.0         0.0   \n",
              "3              1.0          0.0          0.0           0.0         0.0   \n",
              "4              0.0          0.0          0.0           0.0         0.0   \n",
              "...            ...          ...          ...           ...         ...   \n",
              "1195           1.0          0.0          0.0           0.0         1.0   \n",
              "1196           1.0          0.0          0.0           0.0         0.0   \n",
              "1197           0.0          0.0          0.0           0.0         0.0   \n",
              "1198           0.0          0.0          1.0           0.0         0.0   \n",
              "1199           0.0          0.0          1.0           0.0         1.0   \n",
              "\n",
              "      tfidf(york)  tfidf(young)  tfidf(younger)  tfidf(zero)  why_q  \n",
              "0             0.0           1.0             0.0          0.0    0.0  \n",
              "1             0.0           1.0             0.0          0.0    0.0  \n",
              "2             0.0           0.0             0.0          0.0    0.0  \n",
              "3             1.0           0.0             0.0          0.0    0.0  \n",
              "4             0.0           1.0             0.0          0.0    0.0  \n",
              "...           ...           ...             ...          ...    ...  \n",
              "1195          1.0           0.0             0.0          0.0    0.0  \n",
              "1196          0.0           1.0             0.0          0.0    0.0  \n",
              "1197          0.0           0.0             0.0          0.0    0.0  \n",
              "1198          0.0           0.0             0.0          0.0    0.0  \n",
              "1199          0.0           1.0             0.0          0.0    0.0  \n",
              "\n",
              "[1200 rows x 4514 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-268582a0-c933-4145-8733-5942c8f3aa61\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bigram(!_!)</th>\n",
              "      <th>bigram(!_\")</th>\n",
              "      <th>bigram(!_))</th>\n",
              "      <th>bigram(&amp;_nbsp)</th>\n",
              "      <th>bigram('_')</th>\n",
              "      <th>bigram('_,)</th>\n",
              "      <th>bigram('_.)</th>\n",
              "      <th>bigram('_a)</th>\n",
              "      <th>bigram('_and)</th>\n",
              "      <th>bigram('_d)</th>\n",
              "      <th>...</th>\n",
              "      <th>tfidf(wrote)</th>\n",
              "      <th>tfidf(yeah)</th>\n",
              "      <th>tfidf(year)</th>\n",
              "      <th>tfidf(years)</th>\n",
              "      <th>tfidf(yes)</th>\n",
              "      <th>tfidf(york)</th>\n",
              "      <th>tfidf(young)</th>\n",
              "      <th>tfidf(younger)</th>\n",
              "      <th>tfidf(zero)</th>\n",
              "      <th>why_q</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows Ã— 4514 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-268582a0-c933-4145-8733-5942c8f3aa61')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-268582a0-c933-4145-8733-5942c8f3aa61 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-268582a0-c933-4145-8733-5942c8f3aa61');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4e86814e-7f5d-43d8-8cc3-61b781107a62\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e86814e-7f5d-43d8-8cc3-61b781107a62')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4e86814e-7f5d-43d8-8cc3-61b781107a62 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_25dd3f61-4e3e-4e73-8e70-1b1f7ab3e101\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_tfidf_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_25dd3f61-4e3e-4e73-8e70-1b1f7ab3e101 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_tfidf_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_tfidf_train"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Likewise for the TEST split\n",
        "df_tfidf_test = pd.DataFrame(X_test_tfidf.toarray(), columns = feature_names)\n",
        "df_tfidf_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "hz9ZAkkaH0do",
        "outputId": "fd207841-056c-427e-bf64-d27d0820abbc"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     bigram(!_!)  bigram(!_\")  bigram(!_))  bigram(&_nbsp)  bigram('_')  \\\n",
              "0            1.0          0.0          0.0             0.0          0.0   \n",
              "1            0.0          0.0          0.0             0.0          0.0   \n",
              "2            0.0          0.0          0.0             0.0          0.0   \n",
              "3            0.0          0.0          0.0             0.0          0.0   \n",
              "4            0.0          0.0          0.0             0.0          0.0   \n",
              "..           ...          ...          ...             ...          ...   \n",
              "395          0.0          0.0          0.0             0.0          0.0   \n",
              "396          0.0          0.0          0.0             0.0          0.0   \n",
              "397          0.0          0.0          0.0             0.0          0.0   \n",
              "398          0.0          0.0          0.0             0.0          0.0   \n",
              "399          0.0          0.0          0.0             0.0          0.0   \n",
              "\n",
              "     bigram('_,)  bigram('_.)  bigram('_a)  bigram('_and)  bigram('_d)  ...  \\\n",
              "0            0.0          0.0          0.0            0.0          0.0  ...   \n",
              "1            0.0          0.0          0.0            0.0          0.0  ...   \n",
              "2            0.0          0.0          0.0            0.0          0.0  ...   \n",
              "3            0.0          0.0          0.0            0.0          0.0  ...   \n",
              "4            0.0          0.0          0.0            0.0          0.0  ...   \n",
              "..           ...          ...          ...            ...          ...  ...   \n",
              "395          0.0          0.0          0.0            0.0          0.0  ...   \n",
              "396          0.0          0.0          0.0            0.0          0.0  ...   \n",
              "397          0.0          0.0          0.0            0.0          0.0  ...   \n",
              "398          0.0          0.0          0.0            0.0          0.0  ...   \n",
              "399          0.0          0.0          0.0            0.0          0.0  ...   \n",
              "\n",
              "     tfidf(wrote)  tfidf(yeah)  tfidf(year)  tfidf(years)  tfidf(yes)  \\\n",
              "0             0.0          0.0          1.0           0.0         0.0   \n",
              "1             0.0          0.0          1.0           0.0         0.0   \n",
              "2             0.0          0.0          1.0           0.0         1.0   \n",
              "3             0.0          0.0          1.0           0.0         0.0   \n",
              "4             0.0          0.0          0.0           0.0         0.0   \n",
              "..            ...          ...          ...           ...         ...   \n",
              "395           0.0          0.0          0.0           0.0         0.0   \n",
              "396           1.0          0.0          1.0           0.0         0.0   \n",
              "397           1.0          0.0          1.0           0.0         0.0   \n",
              "398           0.0          0.0          1.0           0.0         0.0   \n",
              "399           0.0          0.0          0.0           0.0         0.0   \n",
              "\n",
              "     tfidf(york)  tfidf(young)  tfidf(younger)  tfidf(zero)  why_q  \n",
              "0            0.0           0.0             0.0          0.0    0.0  \n",
              "1            1.0           1.0             0.0          0.0    0.0  \n",
              "2            0.0           0.0             0.0          0.0    0.0  \n",
              "3            0.0           1.0             0.0          0.0    0.0  \n",
              "4            0.0           0.0             0.0          0.0    0.0  \n",
              "..           ...           ...             ...          ...    ...  \n",
              "395          0.0           0.0             0.0          0.0    0.0  \n",
              "396          0.0           1.0             0.0          0.0    0.0  \n",
              "397          0.0           0.0             0.0          0.0    0.0  \n",
              "398          0.0           0.0             0.0          0.0    0.0  \n",
              "399          0.0           1.0             0.0          0.0    0.0  \n",
              "\n",
              "[400 rows x 4514 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f5e66f7-c4b1-4ff0-a3e6-64098e57ee11\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bigram(!_!)</th>\n",
              "      <th>bigram(!_\")</th>\n",
              "      <th>bigram(!_))</th>\n",
              "      <th>bigram(&amp;_nbsp)</th>\n",
              "      <th>bigram('_')</th>\n",
              "      <th>bigram('_,)</th>\n",
              "      <th>bigram('_.)</th>\n",
              "      <th>bigram('_a)</th>\n",
              "      <th>bigram('_and)</th>\n",
              "      <th>bigram('_d)</th>\n",
              "      <th>...</th>\n",
              "      <th>tfidf(wrote)</th>\n",
              "      <th>tfidf(yeah)</th>\n",
              "      <th>tfidf(year)</th>\n",
              "      <th>tfidf(years)</th>\n",
              "      <th>tfidf(yes)</th>\n",
              "      <th>tfidf(york)</th>\n",
              "      <th>tfidf(young)</th>\n",
              "      <th>tfidf(younger)</th>\n",
              "      <th>tfidf(zero)</th>\n",
              "      <th>why_q</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows Ã— 4514 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f5e66f7-c4b1-4ff0-a3e6-64098e57ee11')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f5e66f7-c4b1-4ff0-a3e6-64098e57ee11 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f5e66f7-c4b1-4ff0-a3e6-64098e57ee11');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c6b8f4d9-c9e7-4c90-bf3b-0b9039a5f6f6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6b8f4d9-c9e7-4c90-bf3b-0b9039a5f6f6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c6b8f4d9-c9e7-4c90-bf3b-0b9039a5f6f6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f72fb462-065d-4be0-a38d-fae2c0bd84da\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_tfidf_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f72fb462-065d-4be0-a38d-fae2c0bd84da button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_tfidf_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_tfidf_test"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 7"
      ],
      "metadata": {
        "id": "iC3EBV5ZIm2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(text):\n",
        "    tokens = preprocess(nltk.word_tokenize(text)) #preprocess step from before\n",
        "\n",
        "     # Remove punctuation-only tokens\n",
        "    tokens = [t for t in tokens if not all(c in string.punctuation for c in t)]\n",
        "\n",
        "    # Removing numbers from reviews\n",
        "    tokens = [t for t in tokens if not t.isdigit()]\n",
        "\n",
        "    # Removing first person pronouns\n",
        "    tokens = [t for t in tokens if t.lower() not in ['i', 'me', 'my', 'mine', 'myself']]\n",
        "\n",
        "    # Removing _NEG tags\n",
        "    tokens = [t for t in tokens if not t.endswith('_NEG')]\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "-wFcPKiUKB6l"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "vectorizer = TfidfVectorizer(analyzer=normalize, token_pattern=None)\n",
        "X_tfidf = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Get the vocabulary (terms)\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert the TFâ€“IDF sparse matrix to a dense array\n",
        "#    and build a DataFrame whose columns are the term names:\n",
        "df_tfidf = pd.DataFrame(\n",
        "    X_tfidf.toarray(),    # shape: (n_docs, n_terms)\n",
        "    columns=terms\n",
        ")\n",
        "\n",
        "# Inspect\n",
        "print(df_tfidf.shape)\n",
        "print(df_tfidf)  #\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FYZLwkPIn-t",
        "outputId": "93cc3f31-bac7-4ae2-d878-0aab1b3d754a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1200, 32759)\n",
            "        \u0005  \u0013goodies  \u0013suspend  \u0013they  \u0013white\u0014    \u0014    \u0016       are   will  \\\n",
            "0     0.0       0.0       0.0    0.0      0.0  0.0  0.0  0.000000    0.0   \n",
            "1     0.0       0.0       0.0    0.0      0.0  0.0  0.0  0.000000    0.0   \n",
            "2     0.0       0.0       0.0    0.0      0.0  0.0  0.0  0.000000    0.0   \n",
            "3     0.0       0.0       0.0    0.0      0.0  0.0  0.0  0.000000    0.0   \n",
            "4     0.0       0.0       0.0    0.0      0.0  0.0  0.0  0.000000    0.0   \n",
            "...   ...       ...       ...    ...      ...  ...  ...       ...    ...   \n",
            "1195  0.0       0.0       0.0    0.0      0.0  0.0  0.0  0.000000    0.0   \n",
            "1196  0.0       0.0       0.0    0.0      0.0  0.0  0.0  0.000000    0.0   \n",
            "1197  0.0       0.0       0.0    0.0      0.0  0.0  0.0  0.028588    0.0   \n",
            "1198  0.0       0.0       0.0    0.0      0.0  0.0  0.0  0.000000    0.0   \n",
            "1199  0.0       0.0       0.0    0.0      0.0  0.0  0.0  0.000000    0.0   \n",
            "\n",
            "         would  ...  zorg  zorro  zucker  zuehlke  zuko  zulu  zweibel  zwick  \\\n",
            "0     0.000000  ...   0.0    0.0     0.0      0.0   0.0   0.0      0.0    0.0   \n",
            "1     0.000000  ...   0.0    0.0     0.0      0.0   0.0   0.0      0.0    0.0   \n",
            "2     0.000000  ...   0.0    0.0     0.0      0.0   0.0   0.0      0.0    0.0   \n",
            "3     0.000000  ...   0.0    0.0     0.0      0.0   0.0   0.0      0.0    0.0   \n",
            "4     0.000000  ...   0.0    0.0     0.0      0.0   0.0   0.0      0.0    0.0   \n",
            "...        ...  ...   ...    ...     ...      ...   ...   ...      ...    ...   \n",
            "1195  0.024212  ...   0.0    0.0     0.0      0.0   0.0   0.0      0.0    0.0   \n",
            "1196  0.000000  ...   0.0    0.0     0.0      0.0   0.0   0.0      0.0    0.0   \n",
            "1197  0.000000  ...   0.0    0.0     0.0      0.0   0.0   0.0      0.0    0.0   \n",
            "1198  0.000000  ...   0.0    0.0     0.0      0.0   0.0   0.0      0.0    0.0   \n",
            "1199  0.000000  ...   0.0    0.0     0.0      0.0   0.0   0.0      0.0    0.0   \n",
            "\n",
            "      zwigoff  zycie  \n",
            "0         0.0    0.0  \n",
            "1         0.0    0.0  \n",
            "2         0.0    0.0  \n",
            "3         0.0    0.0  \n",
            "4         0.0    0.0  \n",
            "...       ...    ...  \n",
            "1195      0.0    0.0  \n",
            "1196      0.0    0.0  \n",
            "1197      0.0    0.0  \n",
            "1198      0.0    0.0  \n",
            "1199      0.0    0.0  \n",
            "\n",
            "[1200 rows x 32759 columns]\n"
          ]
        }
      ]
    }
  ]
}